{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML460 Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "13P7aWyDuYnCqxEfbJcYtPNM9TXSAPkq6",
      "authorship_tag": "ABX9TyPRqUxsihXt8TiEnnYf7tLt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sagar-11/21cs460_group20/blob/main/ML460_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhk1KqPkYmVg"
      },
      "source": [
        "# **Project Midway**\n",
        "### Machine Translation under atypical use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDiFGq-vXOMb"
      },
      "source": [
        "# *Synopsis of papers*\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaDdgPNzW97Q"
      },
      "source": [
        "## 1. Malinin, A., Band, N., Ganshin, Chesnokov, G., Gal, Gales, M., Noskov, A., Ploskonosov, A., Prokhorenkova, L., Provilkov, I., Raina, V., Raina, V., Roginskiy, D., Shmatova, M., Tigar, P., & Yangel, B. (2021). Shifts: A Dataset of Real Distributional Shift Across Multiple Large-Scale Tasks. arXiv preprint arXiv:2107.07455 .\n",
        "---\n",
        "* Recall: We want models that are robust to distributional shifts i.e they perform well on data 'in the wild' which could be very different than our training data\n",
        "* Additionally we want it to give reliable uncertainty estimates on its prediction so we know we to trust it.\n",
        "* Datasets: WMT'20en-ru, Newstest'19, WMT'19 MTNT reddit, Global voices, Shifts reddit.\n",
        "* For predictive performance standard metrics can be used: BLEU, eGLEU,maxGLEU.\n",
        "$$ eGLEU = \\frac{1}{N}\\sum_{i=1}^{N}\\sum_{h=1}^{H}GLEU_{i,h}.w_{i,h}$$ , $$\n",
        "\\sum_{h=1}^{H}w_h = 1\n",
        "$$\n",
        "$$maxGLEU = \\frac{1}{N}\\sum_{i=1}^{N}max_h[GLEU_{i,h}]$$\n",
        "* For the quality of uncertainity estimates we can use dicrimainatory power between 'indomain' and 'outdomain' using AUPR and AUROC but not a good idea.\n",
        "* Instead authors propose area under error retention curves for joint estimates.\n",
        "* Authors have used an ensemble of transformer-big trained using a fork of fairseq. They have used uncertainty estimates from a referenced paper (both discussed below)\n",
        "\n",
        "|Data    | R-AUC   | F1-AUC  | ROC-AUC  |\n",
        "|--------|---------|---------|----------|\n",
        "| dev    |33.22±0.48| 0.428±0.003| 68.9±0.28|\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL3Ms0vDte9x"
      },
      "source": [
        "##2. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł. & Polosukhin, I. (2017). Attention is all you need. Advances in Neural Information Processing Systems (p./pp. 5998--6008), .\n",
        "---\n",
        "* Why do we need Transformers?\n",
        "* Translation is autoregressive task where given an input sequence we must return an output sequence.\n",
        "* RNNs are neural networks that roll out in discrete time steps and thus have been used in vec2seq, seq2vec, seq2seq tasks\n",
        "* They suffer from a few major drawbacks: They are slow to train, Vanishing Gradients hence do not perform good for longer sentences.\n",
        "* The LSTM block was introduced to solve the problem of vanishing gradients but they are even slower to train.\n",
        "* The problem is their sequential nature that do not allow parallelisation\n",
        "* The self-attention layers were added, with the idea that not all words are equally important for translation so only focus on some parts.\n",
        "$$\n",
        "\\text { Attention }(Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}\\right) V\n",
        "$$\n",
        "$$\n",
        "\\begin{aligned}\n",
        "P E_{(p o s, 2 i)} &=\\sin \\left(p o s / 10000^{2 i / d_{\\text {model }}}\\right) \\\\\n",
        "P E_{(\\text {pos }, 2 i+1)} &=\\cos \\left(p o s / 10000^{2 i / d_{\\text {model }}}\\right)\n",
        "\\end{aligned}\n",
        "$$\n",
        "* Because of their significant improvements they have became the base for many other sequence prediction and NLP models. (BERT, GPT3)\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1GfBo38rzx0jz0mMEDoNv9ByS_svC6NmL)\n",
        "\n",
        "We will go through some other implementaion details later as many implementations are already available.\n",
        "[Tensorflow tutorial on details of the Transformer model](https://www.tensorflow.org/text/tutorials/transformer#setup)\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOJH4k_gsDGR"
      },
      "source": [
        "##3.  Malinin, A., & Gales, M. (2020). Uncertainty Estimation in Autoregressive Structured Prediction. arXiv preprint arXiv:2002.07650.\n",
        "---\n",
        "* Their goal is to give unsupervised uncertainty estimates in autoregressive tasks at both token and sentence level.\n",
        "* The authors claim that there are two types of uncertainties Knowledge and Data\n",
        "* Knowledge uncertainty captures the uncertainty due to the lack of understanding of data by the model.\n",
        "* Data uncertainty is the intrinsic uncertainty in the data\n",
        "* The authors take a bayesian approach, they assume that model parameter $\\mathbf{\\theta}$ is a random variable with a prior $p(\\mathbf{\\theta})$ \n",
        "* The predictive Posterior given the data $p(\\mathbf{\\theta}| \\mathcal{D})$ is intractable so we take $q(\\mathbf{\\theta}) \\approx p(\\mathbf{\\theta}| \\mathcal{D}) $\n",
        "* Using entropy chain rules we can write total uncertainity = know. uncertainty + data uncertainty\n",
        "* Taking inspiration from this they use mutual information between y and $\\theta$ to quantify ensemble diversity.\n",
        "* Next they use EPKL and reverse mutual information to measure model diversity/uncertainty\n",
        "* They explore a few properties of the three measures give monte carlo approximates to calculate them.\n",
        "* They also explore how different ways of ensemble prediction effects uncertainty estimates.\n",
        "$$\n",
        "\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\mathcal{D})=\\mathbb{E}_{\\mathbf{q}(\\theta)}[\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\boldsymbol{\\theta})] \\approx \\frac{1}{M} \\sum_{m=1}^{M} \\mathrm{P}\\left(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\boldsymbol{\\theta}^{(m)}\\right), \\boldsymbol{\\theta}^{(m)} \\sim \\mathrm{q}(\\boldsymbol{\\theta}) \\approx \\mathrm{p}(\\boldsymbol{\\theta} \\mid \\mathcal{D})\n",
        "$$\n",
        "$$\n",
        "\\mathcal{H}[\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\mathcal{D})]=\\mathbb{E}_{\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\mathcal{D})}[-\\ln \\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\mathcal{D})]=-\\sum_{\\boldsymbol{y} \\in \\mathcal{Y}} \\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\mathcal{D}) \\ln \\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\mathcal{D})\n",
        "$$\n",
        "$$\n",
        "\\underbrace{\\mathcal{I}[\\boldsymbol{y}, \\boldsymbol{\\theta} \\mid \\boldsymbol{x}, \\mathcal{D}]}_{\\text {Know. Uncertainty }}=\\mathbb{E}_{\\mathbf{q}(\\boldsymbol{\\theta})}\\left[\\mathbb{E}_{\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\boldsymbol{\\theta})}\\left[\\ln \\frac{\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\boldsymbol{\\theta})}{\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\mathcal{D})}\\right]\\right]=\\underbrace{\\hat{\\mathcal{H}}[\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\mathcal{D})]}_{\\text {Total Uncertainty }}-\\underbrace{\\mathbb{E}_{\\mathbf{q}(\\boldsymbol{\\theta})}[\\hat{\\mathcal{H}}[\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\boldsymbol{\\theta})]]}_{\\text {Expected Data Uncertainty }}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathcal{K}[\\boldsymbol{y}, \\boldsymbol{\\theta} \\mid \\boldsymbol{x}, \\mathcal{D}]=\\mathbb{E}_{\\mathbf{q}(\\boldsymbol{\\theta}) \\mathbf{q}(\\tilde{\\theta})}\\left[\\mathbb{E}_{\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\boldsymbol{\\theta})}\\left[\\ln \\frac{\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\boldsymbol{\\theta})}{\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\tilde{\\boldsymbol{\\theta}})}\\right]\\right] \\quad \\mathrm{q}(\\boldsymbol{\\theta}) \\approx \\mathrm{p}(\\boldsymbol{\\theta} \\mid \\mathcal{D})\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathcal{M}[\\boldsymbol{y}, \\boldsymbol{\\theta} \\mid \\boldsymbol{x}, \\mathcal{D}]=\\mathbb{E}_{\\mathrm{q}(\\boldsymbol{\\theta})}\\left[\\mathbb{E}_{\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\mathcal{D})}\\left[\\ln \\frac{\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\mathcal{D})}{\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\boldsymbol{\\theta})}\\right]\\right], \\quad \\mathrm{q}(\\boldsymbol{\\theta}) \\approx \\mathrm{p}(\\boldsymbol{\\theta} \\mid \\mathcal{D})\n",
        "$$\n",
        "$$\n",
        "\\hat{\\mathcal{H}}_{\\mathrm{C}-\\mathrm{MC}}^{(S)}[\\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\mathcal{D})] \\approx \\frac{1}{S} \\sum_{s=1}^{S} \\frac{1}{L^{(s)}} \\sum_{l=1}^{L^{(s)}} \\mathcal{H}\\left[\\mathrm{P}\\left(y_{l} \\mid \\boldsymbol{y}_{<l}^{(s)}, \\boldsymbol{x}, \\mathcal{D}\\right)\\right], \\quad \\forall \\boldsymbol{y}_{<l}^{(s)} \\subset \\boldsymbol{y}^{(s)} \\sim \\mathrm{P}(\\boldsymbol{y} \\mid \\boldsymbol{x}, \\mathcal{D})\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RWEKjujt9H9"
      },
      "source": [
        "## 4. Wang, Y., Wu, L., Xia, Y., Qin, T., Zhai, C., & Liu, T.-Y. (2020). Transductive Ensemble Learning for Neural Machine Translation. Proceedings of the AAAI Conference on Artificial Intelligence, 34(04), 6291-6298.\n",
        "---\n",
        "\n",
        "* While ensemble learning in effective in many scenarios it has some limitations in some cases.\n",
        "* When there are strong single models, ensemble based techinques do not give much improvement\n",
        "* Also in the case of many models ensemble techinques do not offer much\n",
        "* The authors thus propose a technique based on transductive learning to address these issues. They claim that there idea performs better based on other ensemble techniques like Knowledge distillation.\n",
        "* The key idea is to generate a synthetic dataset from the validation and test set and generating their translation from ensemble then fine tuning any single model on this dataset so as to minimise a loss function. Then choose the best model that performs well on the validation set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMFYxhTbuG0M"
      },
      "source": [
        "* Paul Michel, Tatsunori B. Hashimoto, & Graham Neubig (2021). Modeling the Second Player in Distributionally Robust Optimization. ArXiv, abs/2103.10282.\n",
        "* Peters, M., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2018). Deep contextualized word representations. In Proc. of NAACL.\n",
        "* Zhang J, Mani I. KNN approach to unbalanced data distributions: a case study involving information extraction. In: Proceedings of the ICML’2003 workshop on learning from imbalanced datasets. 2003.\n",
        "* Lucia Specia, Zhenhao Li, J. Pino, Vishrav Chaudhary, Francisco Guzmán, Graham Neubig, Nadir Durrani, Yonatan Belinkov, Philipp Koehn, Hassan Sajjad, Paul Michel, & Xian Li (2020). Findings of the WMT 2020 Shared Task on Machine Translation Robustness. In WMT.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvN3QbyzF6k4"
      },
      "source": [
        "# *Implementation and Details*\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPn98vJUVlOA",
        "outputId": "bf505ba7-30f7-4eb6-f805-4dd7942a5a1e"
      },
      "source": [
        " # Directory for Project\n",
        " %cd /content/drive/MyDrive/ML460\\ Project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML460 Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq0PBn_aZG9s"
      },
      "source": [
        "# downloads dataset, creates output dir wmt20_en_ru\n",
        "!bash prepare_data.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKCJUG2JevoI",
        "outputId": "1a5f2953-65f0-420d-9f40-e277b303708b"
      },
      "source": [
        "# converts some tsv files to csv, pre-process train data\n",
        "# pre- process train data:- Normalise punctuation, non-print character removed\n",
        "# and tokenise using Mosesdecoder. token files stored in wmt20../tmp\n",
        "!bash prepare_data.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'mosesdecoder'...\n",
            "remote: Enumerating objects: 148070, done.\u001b[K\n",
            "remote: Counting objects: 100% (498/498), done.\u001b[K\n",
            "remote: Compressing objects: 100% (206/206), done.\u001b[K\n",
            "remote: Total 148070 (delta 315), reused 433 (delta 289), pack-reused 147572\u001b[K\n",
            "Receiving objects: 100% (148070/148070), 129.86 MiB | 7.14 MiB/s, done.\n",
            "Resolving deltas: 100% (114341/114341), done.\n",
            "Checking out files: 100% (3489/3489), done.\n",
            "Cloning into 'subword-nmt'...\n",
            "remote: Enumerating objects: 580, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 580 (delta 0), reused 1 (delta 0), pack-reused 576\u001b[K\n",
            "Receiving objects: 100% (580/580), 237.41 KiB | 3.39 MiB/s, done.\n",
            "Resolving deltas: 100% (349/349), done.\n",
            "pre-processing train data...\n",
            "rm: cannot remove 'wmt20_en_ru/tmp/train.tags.en-ru.tok.en': No such file or directory\n",
            "train-data/paracrawl-release1.en-ru.zipporah0-dedup-clean\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 24\n",
            "train-data/commoncrawl.ru-en\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 24\n",
            "train-data/en-ru/UNv1.0.en-ru\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 24\n",
            "train-data/1mcorpus/corpus.en_ru.1m\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 24\n",
            "train-data/news-commentary-v15.en-ru\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 24\n",
            "train-data/WikiMatrix.v1.en-ru.langid\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 24\n",
            "train-data/wikititles-v2.ru-en\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 24\n",
            "rm: cannot remove 'wmt20_en_ru/tmp/train.tags.en-ru.tok.ru': No such file or directory\n",
            "train-data/paracrawl-release1.en-ru.zipporah0-dedup-clean\n",
            "Tokenizer Version 1.1\n",
            "Language: ru\n",
            "Number of threads: 24\n",
            "train-data/commoncrawl.ru-en\n",
            "Tokenizer Version 1.1\n",
            "Language: ru\n",
            "Number of threads: 24\n",
            "train-data/en-ru/UNv1.0.en-ru\n",
            "Tokenizer Version 1.1\n",
            "Language: ru\n",
            "Number of threads: 24\n",
            "train-data/1mcorpus/corpus.en_ru.1m\n",
            "Tokenizer Version 1.1\n",
            "Language: ru\n",
            "Number of threads: 24\n",
            "train-data/news-commentary-v15.en-ru\n",
            "Tokenizer Version 1.1\n",
            "Language: ru\n",
            "Number of threads: 24\n",
            "train-data/WikiMatrix.v1.en-ru.langid\n",
            "Tokenizer Version 1.1\n",
            "Language: ru\n",
            "Number of threads: 24\n",
            "train-data/wikititles-v2.ru-en\n",
            "Tokenizer Version 1.1\n",
            "Language: ru\n",
            "Number of threads: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4OgD6KdRqWU",
        "outputId": "9c57a9bf-6751-4e71-fc95-0af9e5345232"
      },
      "source": [
        "#same as above for news dataset\n",
        "!bash prepare_data.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing back-trans news dataset\n",
            "Tokenizer Version 1.1\n",
            "Language: en\n",
            "Number of threads: 24\n",
            "Tokenizer Version 1.1\n",
            "Language: ru\n",
            "Number of threads: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEVnoSZJ1HbO",
        "outputId": "eb5ffc63-5ba9-4462-d4ed-98e31116bb86"
      },
      "source": [
        "# remove duplications\n",
        "!bash prepare_data.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Remove Deplications, clean data\n",
            "prepare_data.sh: line 123: 20469 Broken pipe             paste $tmp/train.tags.$lang.tok.en $tmp/train.tags.$lang.tok.ru\n",
            "     20470 Killed                  | python $CLEAN_DATA --directions en-ru --no-zero-len --max-sent-len 1024 --no-bad-utf --max-jaccard-coef-exclusive 0.05 --filter-equality >> $tmp/tmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hyuefv2lky9H",
        "outputId": "01890484-e4dd-436f-a2f9-d2ba0e31ff8d"
      },
      "source": [
        "# splitting train and valid\n",
        "!bash prepare_data.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "splitting train and valid...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvLcfJ1J-GV0",
        "outputId": "d2f10b15-8357-4c0b-df9d-7bd2327571f2"
      },
      "source": [
        "!bash prepare_data.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learn_bpe.py on wmt20_en_ru/tmp/train.en-ru...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhHm90BAFn8K",
        "outputId": "7bc65bdc-665e-41f8-b2e5-9180256f53e2"
      },
      "source": [
        "!bash prepare_data.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "apply_bpe.py to train.en...\n",
            "apply_bpe.py to valid.en...\n",
            "apply_bpe.py to test19.en...\n",
            "apply_bpe.py to reddit_dev.en...\n",
            "apply_bpe.py to train.ru...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XTOx35nRgJc",
        "outputId": "d599e185-a218-4b0d-b27d-ad746e2860e4"
      },
      "source": [
        "!bash prepare_data.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "apply_bpe.py to train.ru...\n",
            "apply_bpe.py to valid.ru...\n",
            "apply_bpe.py to test19.ru...\n",
            "apply_bpe.py to reddit_dev.ru...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-XKd0fSpmBL",
        "outputId": "b3ff4bab-a72d-438d-e46f-d939c1e8f976"
      },
      "source": [
        "#runs a script to clean and outs in prep/train and prep/valid\n",
        "!bash prepare_data.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clean-corpus.perl: processing wmt20_en_ru/tmp/bpe.train.en & .ru to wmt20_en_ru/train, cutoff 1-250, ratio 1.5\n",
            "..........(100000)..........(200000)..........(300000)..........(400000)..........(500000)..........(600000)..........(700000)..........(800000)..........(900000)..........(1000000)..........(1100000)..........(1200000)..........(1300000)..........(1400000)..........(1500000)..........(1600000)..........(1700000)..........(1800000)..........(1900000)..........(2000000)..........(2100000)..........(2200000)..........(2300000)..........(2400000)..........(2500000)..........(2600000)..........(2700000)..........(2800000)..........(2900000)..........(3000000)..........(3100000)..........(3200000)..........(3300000)..........(3400000)..........(3500000)..........(3600000)..........(3700000)..........(3800000)..........(3900000)..........(4000000)..........(4100000)..........(4200000)..........(4300000)..........(4400000)..........(4500000)..........(4600000)..........(4700000)..........(4800000)..........(4900000)..........(5000000)..........(5100000)..........(5200000)..........(5300000)..........(5400000)..........(5500000)..........(5600000)..........(5700000)..........(5800000)..........(5900000)..........(6000000)..........(6100000)..........(6200000)..........(6300000)..........(6400000)..........(6500000)..........(6600000)..........(6700000)..........(6800000)..........(6900000)..........(7000000)..........(7100000)..........(7200000)..........(7300000)..........(7400000)..........(7500000)..........(7600000)..........(7700000)..........(7800000)..........(7900000)..........(8000000)..........(8100000)..........(8200000)..........(8300000)..........(8400000)..........(8500000)..........(8600000)..........(8700000)..........(8800000)..........(8900000)..........(9000000)..........(9100000)..........(9200000)..........(9300000)..........(9400000)..........(9500000)..........(9600000)..........(9700000)..........(9800000)..........(9900000)..........(10000000)..........(10100000)..........(10200000)..........(10300000)..........(10400000)..........(10500000)..........(10600000)..........(10700000)..........(10800000)..........(10900000)..........(11000000)..........(11100000)..........(11200000)..........(11300000)..........(11400000)..........(11500000)..........(11600000)..........(11700000)..........(11800000)..........(11900000)..........(12000000)..........(12100000)..........(12200000)..........(12300000)..........(12400000)..........(12500000)..........(12600000)..........(12700000)..........(12800000)..........(12900000)..........(13000000)..........(13100000)..........(13200000)..........(13300000)..........(13400000)..........(13500000)..........(13600000)..........(13700000)..........(13800000)..........(13900000)..........(14000000)..........(14100000)..........(14200000)..........(14300000)..........(14400000)..........(14500000)..........(14600000)..........(14700000)..........(14800000)..........(14900000)..........(15000000)..........(15100000)..........(15200000)..........(15300000)..........(15400000)..........(15500000)..........(15600000)..........(15700000)..........(15800000)..........(15900000)..........(16000000)..........(16100000)..........(16200000)..........(16300000)..........(16400000)..........(16500000)..........(16600000)..........(16700000)..........(16800000)..........(16900000)..........(17000000)..........(17100000)..........(17200000)..........(17300000)..........(17400000)..........(17500000)..........(17600000)..........(17700000)..........(17800000)..........(17900000)..........(18000000)..........(18100000)..........(18200000)..........(18300000)..........(18400000)..........(18500000)..........(18600000)..........(18700000)..........(18800000)..........(18900000)..........(19000000)..........(19100000)..........(19200000)..........(19300000)..........(19400000)..........(19500000)..........(19600000)..........(19700000)..........(19800000)..........(19900000)..........(20000000)..........(20100000)..........(20200000)..........(20300000)..........(20400000)..........(20500000)..........(20600000)..........(20700000)..........(20800000)..........(20900000)..........(21000000)..........(21100000)..........(21200000)..........(21300000)..........(21400000)..........(21500000)..........(21600000)..........(21700000)..........(21800000)..........(21900000)..........(22000000)..........(22100000)..........(22200000)..........(22300000)..........(22400000)..........(22500000)..........(22600000)..........(22700000)..........(22800000)..........(22900000)..........(23000000)..........(23100000)..........(23200000)..........(23300000)..........(23400000)..........(23500000)..........(23600000)..........(23700000)..........(23800000)..........(23900000)..........(24000000)..........(24100000)..........(24200000)..........(24300000)..........(24400000)..........(24500000)..........(24600000)..........(24700000)..........(24800000)..........(24900000)..........(25000000)..........(25100000)..........(25200000)..........(25300000)..........(25400000)..........(25500000)..........(25600000)..........(25700000)..........(25800000)..........(25900000)..........(26000000)..........(26100000)..........(26200000)..........(26300000)..........(26400000)..........(26500000)..........(26600000)..........(26700000)..........(26800000)..........(26900000)..........(27000000)..........(27100000)..........(27200000)..........(27300000)..........(27400000)..........(27500000)..........(27600000)..........(27700000)..........(27800000)..........(27900000)..........(28000000)..........(28100000)..........(28200000)..........(28300000)..........(28400000)..........(28500000)..........(28600000)..........(28700000)..........(28800000)..........(28900000)..........(29000000)..........(29100000)..........(29200000)..........(29300000)..........(29400000)..........(29500000)..........(29600000)..........(29700000)..........(29800000)..........(29900000)..........(30000000)..........(30100000)..........(30200000)..........(30300000)..........(30400000)..........(30500000)..........(30600000)..........(30700000)..........(30800000)..........(30900000)..........(31000000)..........(31100000)..........(31200000)..........(31300000)..........(31400000)..........(31500000)..........(31600000)..........(31700000)..........(31800000)..........(31900000)..........(32000000)..........(32100000)..........(32200000)..........(32300000)..........(32400000)..........(32500000)..........(32600000)..........(32700000)..........(32800000)..........(32900000)..........(33000000)..........(33100000)..........(33200000)..........(33300000)..........(33400000)..........(33500000)..........(33600000)..........(33700000)..........(33800000)..........(33900000)..........(34000000)......\n",
            "Input sentences: 34064941  Output sentences:  29815305\n",
            "clean-corpus.perl: processing wmt20_en_ru/tmp/bpe.valid.en & .ru to wmt20_en_ru/valid, cutoff 1-250, ratio 1.5\n",
            "..........(100000)..........(200000)..........(300000)....\n",
            "Input sentences: 344090  Output sentences:  301155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiVOmoSUwd_w"
      },
      "source": [
        "!bash prepare_data.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIgJEbpKyfXY",
        "outputId": "de9bc089-e96a-495e-ab24-089eddca0aa6"
      },
      "source": [
        "# installs a fork of fairseq with uncertainity estimates\n",
        "%cd structured-uncertainty\n",
        "!python3 -m pip install --user --no-deps --editable ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML460 Project/structured-uncertainty\n",
            "Obtaining file:///content/drive/MyDrive/ML460%20Project/structured-uncertainty\n",
            "Installing collected packages: fairseq\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed fairseq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiq2b7yL1SMd",
        "outputId": "6133bcda-f8dd-4aef-a919-1db2b916eb86"
      },
      "source": [
        "%cd .. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ML460 Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8rAirAfz267",
        "outputId": "efbc7017-df1f-42a5-9b6e-adf1a49e76a1"
      },
      "source": [
        "# data into fairseq fmat for training and inference.\n",
        "!python3 structured-uncertainty/preprocess.py  --srcdict baseline-models/dict.en.txt --tgtdict baseline-models/dict.ru.txt --source-lang en --target-lang ru \\\\\n",
        "--trainpref wmt20_en_ru/train --validpref wmt20_en_ru/valid --testpref wmt20_en_ru/test19,wmt20_en_ru/reddit_dev  \\\\\n",
        "--destdir data-bin/wmt20_en_ru --thresholdtgt 0 --thresholdsrc 0  --workers 24"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/wmt20_en_ru', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=1000, lr_scheduler='fixed', memory_efficient_fp16=False, min_loss_scale=0.0001, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer='nag', padding_factor=8, seed=1, source_lang='en', srcdict='baseline-models/dict.en.txt', target_lang='ru', task='translation', tensorboard_logdir='', testpref='wmt20_en_ru/test19,wmt20_en_ru/reddit_dev', tgtdict='baseline-models/dict.ru.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='wmt20_en_ru/train', user_dir=None, validpref='wmt20_en_ru/valid', workers=24)\n",
            "| [en] Dictionary: 43767 types\n",
            "| [en] wmt20_en_ru/train.en: 29815305 sents, 873560493 tokens, 1.91% replaced by <unk>\n",
            "| [en] Dictionary: 43767 types\n",
            "| [en] wmt20_en_ru/valid.en: 344090 sents, 9947580 tokens, 1.97% replaced by <unk>\n",
            "| [en] Dictionary: 43767 types\n",
            "| [en] wmt20_en_ru/test19.en: 1997 sents, 60723 tokens, 1.42% replaced by <unk>\n",
            "| [en] Dictionary: 43767 types\n",
            "| [en] wmt20_en_ru/reddit_dev.en: 1362 sents, 29421 tokens, 1.75% replaced by <unk>\n",
            "| [ru] Dictionary: 48271 types\n",
            "| [ru] wmt20_en_ru/train.ru: 29815305 sents, 873286533 tokens, 2.99% replaced by <unk>\n",
            "| [ru] Dictionary: 48271 types\n",
            "| [ru] wmt20_en_ru/valid.ru: 344090 sents, 9763422 tokens, 3.01% replaced by <unk>\n",
            "| [ru] Dictionary: 48271 types\n",
            "| [ru] wmt20_en_ru/test19.ru: 1997 sents, 69502 tokens, 2.08% replaced by <unk>\n",
            "| [ru] Dictionary: 48271 types\n",
            "| [ru] wmt20_en_ru/reddit_dev.ru: 1362 sents, 31661 tokens, 1.48% replaced by <unk>\n",
            "| Wrote preprocessed data to data-bin/wmt20_en_ru\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUWLDlPc2ipw",
        "outputId": "bd257cd0-7b94-44ae-9711-01fe4c10b01f"
      },
      "source": [
        "# inference using single model\n",
        "!bash single_model.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘single’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysMU_fFmJViX",
        "outputId": "d3e045b7-3826-4bf2-dae4-4d9bfd64acc6"
      },
      "source": [
        "pip install sacrebleu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▋                            | 10 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 20 kB 27.7 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 30 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 40 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 51 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 61 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 71 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 81 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 90 kB 5.8 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (1.19.5)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.4 portalocker-2.3.2 sacrebleu-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIqLbsovO5TG",
        "outputId": "106688be-e2ce-44f0-a75b-bc3db7acdbb0"
      },
      "source": [
        "pip install sacremoses"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 61 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 81 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 92 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 102 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 112 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 122 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 133 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 143 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 153 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 163 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 174 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 184 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 194 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 204 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 215 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 225 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 235 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 245 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 256 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 266 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 276 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 286 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 296 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 307 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 317 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 327 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 337 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 348 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 358 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 368 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 378 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 389 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 399 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 409 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 419 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 430 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 440 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 450 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 460 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 471 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 481 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 491 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 501 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 512 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 522 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 532 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 542 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 552 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 563 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 573 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 583 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 593 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 604 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 614 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 624 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 634 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 645 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 655 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 665 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 675 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 686 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 696 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 706 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 716 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 727 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 737 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 747 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 757 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 768 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 778 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 788 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 798 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 808 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 819 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 829 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 839 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 849 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 860 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 870 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 880 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 890 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 895 kB 12.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.62.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2019.12.20)\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwROmkZyQHOP",
        "outputId": "61eb1225-9e12-400c-bece-ee2f0f637a1d"
      },
      "source": [
        "pip install subword_nmt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting subword_nmt\n",
            "  Downloading subword_nmt-0.3.7-py2.py3-none-any.whl (26 kB)\n",
            "Installing collected packages: subword-nmt\n",
            "Successfully installed subword-nmt-0.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_e03nMbJ7F-",
        "outputId": "07e480f6-ebc7-4b92-faf6-bde2e2ce310a"
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY-kIYQiKBOa",
        "outputId": "04173fb5-753c-46da-f953-f1cce1e85b18"
      },
      "source": [
        "!bash shifts/translation/assessment/eval_single.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"shifts/translation/assessment/evaluate.py\", line 391, in <module>\n",
            "    main()\n",
            "  File \"shifts/translation/assessment/evaluate.py\", line 338, in main\n",
            "    refs_out, hypos_out, ids_out, nlls_out = load_text(args.path_out, beam_width=args.beam_width)\n",
            "  File \"shifts/translation/assessment/evaluate.py\", line 304, in load_text\n",
            "    nlls = -np.loadtxt(os.path.join(path, 'hypo_likelihoods.txt'), dtype=np.float32).reshape([-1, beam_width])\n",
            "ValueError: cannot reshape array of size 3118 into shape (5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGi_8Zn2MTeR",
        "outputId": "3b379ca7-e751-4e31-adab-3088468a3e7c"
      },
      "source": [
        "#trains model frm scrtch\n",
        "!python3 structured-uncertainty/train.py data-bin/wmt20_en_ru --arch transformer_wmt_en_de_big --share-decoder-input-output-embed --fp16 --memory-efficient-fp16 --num-workers 16 --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 --dropout 0.1 --weight-decay 0.0001 --criterion label_smoothed_cross_entropy --label-smoothing 0.1 --max-tokens 5120 --save-dir MODEL_DIR --max-update 50000 --update-freq 16 --keep-last-epochs 10 --seed 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de_big', attention_dropout=0.1, best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.0, clip_value=0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt20_en_ru', dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=10, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=1000, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=5120, max_tokens_valid=5120, max_update=50000, maximize_best_checkpoint_metric=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_lr=-1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_token_positional_embeddings=False, num_workers=16, optimizer='adam', optimizer_overrides='{}', patience=-1, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='MODEL_DIR', save_interval=1, save_interval_updates=0, seed=0, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[16], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001)\n",
            "| [en] dictionary: 43768 types\n",
            "| [ru] dictionary: 48272 types\n",
            "| loaded 344090 examples from: data-bin/wmt20_en_ru/valid.en-ru.en\n",
            "| loaded 344090 examples from: data-bin/wmt20_en_ru/valid.en-ru.ru\n",
            "| data-bin/wmt20_en_ru valid en-ru 344090 examples\n",
            "TransformerModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embed_tokens): Embedding(43768, 1024, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embed_tokens): Embedding(48272, 1024, padding_idx=1)\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "| model transformer_wmt_en_de_big, criterion LabelSmoothedCrossEntropyCriterion\n",
            "| num. model params: 270606336 (num. trained: 270606336)\n",
            "| training on 1 GPUs\n",
            "| max tokens per GPU = 5120 and max sentences per GPU = None\n",
            "| no existing checkpoint found MODEL_DIR/checkpoint_last.pt\n",
            "| loading train data for epoch 0\n",
            "| loaded 29815305 examples from: data-bin/wmt20_en_ru/train.en-ru.en\n",
            "| loaded 29815305 examples from: data-bin/wmt20_en_ru/train.en-ru.ru\n",
            "| data-bin/wmt20_en_ru train en-ru 29815305 examples\n",
            "| WARNING: your device does NOT support faster training with --fp16, please switch to FP32 which is likely to be faster\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "| epoch 001:   0% 0/11750 [00:00<?, ?it/s]| WARNING: overflow detected, setting loss scale to: 64.0\n",
            "| epoch 001:   0% 1/11750 [03:00<590:14:00, 180.85s/it]| WARNING: overflow detected, setting loss scale to: 32.0\n",
            "| epoch 001:   0% 2/11750 [05:42<553:41:02, 169.67s/it]| WARNING: overflow detected, setting loss scale to: 16.0\n",
            "| epoch 001:   0% 3/11750 [08:29<549:04:20, 168.27s/it]| WARNING: overflow detected, setting loss scale to: 8.0\n",
            "| epoch 001:   0% 4/11750 [11:18<550:21:07, 168.68s/it]| WARNING: overflow detected, setting loss scale to: 4.0\n",
            "| epoch 001:   0% 5/11750 [14:14<559:10:37, 171.40s/it]/content/drive/MyDrive/ML460 Project/structured-uncertainty/fairseq/optim/adam.py:160: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n",
            "  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
            "| epoch 001:   1% 60/11750 [2:51:16<544:49:18, 167.78s/it, loss=15.343, nll_loss=15.234, ppl=38542.8, wps=384, ups=0, wpb=74234.127, bsz=2560.145, num_updates=55, lr=6.875e-06, gnorm=6.747, clip=0.000, oom=0.000, loss_scale=4.000, wall=10633, train_wall=10250]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVdh2TVoHfGH",
        "outputId": "d2c6fa63-6bdf-416e-8ed5-9296d58cda6b"
      },
      "source": [
        "!python3 structured-uncertainty/interactive.py \\\n",
        "    --path baseline-models/model1.pt baseline-models/ \\\n",
        "    --beam 5 --source-lang en --target-lang ru \\\n",
        "    --tokenizer moses \\\n",
        "    --bpe subword_nmt --bpe-codes wmt20_en_ru/code \\\n",
        "    --compute-uncertainty"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(all_gather_list_size=16384, beam=5, bpe='subword_nmt', bpe_codes='wmt20_en_ru/code', bpe_separator='@@', buffer_size=1, compute_uncertainty=True, cpu=False, criterion='cross_entropy', data='baseline-models/', dataset_impl=None, decoding_format=None, diverse_beam_groups=-1, diverse_beam_strength=0.5, empty_cache_freq=0, ensemble_sum_prod=False, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', input='-', iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, left_pad_source='True', left_pad_target='False', lenpen=1, load_alignments=False, log_format=None, log_interval=1000, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=200, max_sentences=1, max_source_positions=1024, max_target_positions=1024, max_tokens=None, memory_efficient_fp16=False, min_len=1, min_loss_scale=0.0001, model_overrides='{}', momentum=0.99, moses_no_dash_splits=False, moses_no_escape=False, moses_source_lang=None, moses_target_lang=None, nbest=1, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, num_shards=1, num_workers=1, optimizer='nag', path='baseline-models/model1.pt', prefix_size=0, print_alignment=False, print_step=False, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, results_path=None, retain_iter_history=False, sacrebleu=False, sampling=False, sampling_topk=-1, sampling_topp=-1.0, score_reference=False, seed=1, shard_id=0, skip_invalid_size_inputs_valid_test=False, source_lang='en', target_lang='ru', task='translation', temperature=1.0, tensorboard_logdir='', threshold_loss_scale=None, tokenizer='moses', truncate_source=False, unkpen=0, unnormalized=False, upsample_primary=1, user_dir=None, warmup_updates=0, weight_decay=0.0)\n",
            "| [en] dictionary: 43768 types\n",
            "| [ru] dictionary: 48272 types\n",
            "| loading model(s) from baseline-models/model1.pt\n",
            "| Type the input sentence and press return:\n",
            "lets us celebrate\n",
            "Traceback (most recent call last):\n",
            "  File \"structured-uncertainty/interactive.py\", line 195, in <module>\n",
            "    cli_main()\n",
            "  File \"structured-uncertainty/interactive.py\", line 191, in cli_main\n",
            "    main(args)\n",
            "  File \"structured-uncertainty/interactive.py\", line 150, in main\n",
            "    translations = task.inference_step(generator, models, sample)\n",
            "  File \"/content/drive/MyDrive/ML460 Project/structured-uncertainty/fairseq/tasks/fairseq_task.py\", line 307, in inference_step\n",
            "    return generator.generate(models, sample, prefix_tokens=prefix_tokens)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/ML460 Project/structured-uncertainty/fairseq/sequence_generator.py\", line 717, in generate\n",
            "    assert len(models) > 1\n",
            "AssertionError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4CJXjOIVFNf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3A9v40FYUAm"
      },
      "source": [
        "# Post Midway\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eahZGjLQbd6c"
      },
      "source": [
        "* Work with multi30k, pytorch, fairseq libarary, fix errors\n",
        "* Focus on uncertainty estimates, find other ways to jointly asses performance and uncertainty. \n",
        "* Report writing and Website maintenance. "
      ]
    }
  ]
}