<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<h2 id="project-proposal">Project Proposal</h2>
<h1 id="machine-translation-under-atypical-use.">Machine translation under atypical use.</h1>
<p>Machine translation is the process of converting a text from a source language to target language by the use of machine learning algorithms The inherent complexity of language means that having a rule based approach to solve the problem would be tedious and inefficient, hence the need for machine learning based algorithms. Neural Machine learning methods have found use in modelling the ambiguity and flexibility of h human language, but they lack predictability and are trained on corpora based on 'formal use' and perform poorly on text 'in the wild'. Hence in this project we will try to build methods/models that are trained on standard corpora but also perform well on distributionally shfited database i.e. text with the use of profanities, punctuation errors, grammatical mistakes, slangs etc.</p>
<h1 id="dataset">Dataset</h1>
<p>For the training we will use standard dataset like the WMT’20 English-Russian corpus, English-Russian Newstest’19 and the corpus of news data collected from GlobalVoices News service. The text in these is mostly used formally. To check our evaluation on shifted dataset we will use Reddit corpus prepared for the WMT’19 robustness challenge. These dataset is annotated by expert human translators and supplied by the shifts challenge team (NeurIPS 2021). This dataset is tagged with the following anomalies:- Punctuation anomalies, Capitalisation anomalies, Fluency anomalies, Slang anomalies, Emoji anomalies and Tags anomalies. The method of evaluation for the robustness and uncertainty in the prediction will be through area under error - retention curves.</p>
<h1 id="previous-methods-and-baselines.">Previous methods and baselines.</h1>
<p>For the baseline we use an ensemble of 3 transformers-big models trained on the WMT'20 En-Ru Corpus. Some of the previous of robust models have been done of small scale image classification problems but not on multi - modal problems like translation where multiple correct sentences are possible for one input sentence. Such approaches have been extended to structures prediction tasks like ours. They can be characterised by Ensemble and sampling based, Prior networks and temperature scaling.</p>
<h1 id="our-approach-and-schedule.">Our approach and Schedule.</h1>
<p>Upto midway: Do statistical analysis on the dataset, try existing ensemble based methods and existing techniques on robust learning. After midway: Try to include ELMO word embeddings, implement a paper on max-min robust optimisation, assessment and optimisation of the models. Our objective will be to improve baseline performance, try to come with additional measure for uncertainity determination and get to the evaluation leaderboards.</p>
<h1 id="relevant-papers">Relevant Papers</h1>
<ol style="list-style-type: decimal">
<li>Wang, Y., Wu, L., Xia, Y., Qin, T., Zhai, C., &amp; Liu, T.-Y. (2020). Transductive Ensemble Learning for Neural Machine Translation. Proceedings of the AAAI Conference on Artificial Intelligence, 34(04), 6291-6298.</li>
<li>Paul Michel, Tatsunori B. Hashimoto, &amp; Graham Neubig (2021). Modeling the Second Player in Distributionally Robust Optimization. ArXiv, abs/2103.10282.</li>
<li>Peters, M., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., &amp; Zettlemoyer, L. (2018). Deep contextualized word representations. In Proc. of NAACL.</li>
<li>Malinin, A., Band, N., Ganshin, Chesnokov, G., Gal, Gales, M., Noskov, A., Ploskonosov, A., Prokhorenkova, L., Provilkov, I., Raina, V., Raina, V., Roginskiy, D., Shmatova, M., Tigar, P., &amp; Yangel, B. (2021). Shifts: A Dataset of Real Distributional Shift Across Multiple Large-Scale Tasks. arXiv preprint arXiv:2107.07455.</li>
</ol>
</body>
</html>
